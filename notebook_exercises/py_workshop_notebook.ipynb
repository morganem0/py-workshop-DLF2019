{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Python Tools for Metadata Assessment: 55-minute workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome\n",
    "\n",
    "Welcome to the workshop! This is meant to be a a fun and beginner-friendly introduction to a few useful Python tools, in the context of exploring and manipulating tabular metadata for digital collections.   \n",
    "\n",
    "In this session, we will focus on some basic functions of Python's pandas data analysis library. We will use pandas for exploring, filtering, reshaping, and merging datasets. \n",
    "\n",
    "This notebook provides code that you can execute to see results and generate outputs in the notebook itself, as well as explanations for the examples and exercises we'll be working through together. \n",
    "\n",
    "This workshop will be very quick. We will not be able to get through everything. So, this notebook also includes: a couple bonus examples, and a list of recommended resources for further exploration on your own. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "* [Workshop Plan](#wplan)\n",
    "* [Using the Jupyter Notebook](#usingjn)\n",
    "    * [Exercise 1: Run Code Cells](#ex1)\n",
    "    * [Exercise 2: Add New Code](#ex2)\n",
    "    * [More Notebook Exercises](#mjn)\n",
    "* [Python/pandas Examples with Collections Metadata](#ppe)\n",
    "    * [Metadata Example 1: Explore a dataset](#md1)\n",
    "        * [Exercise 3: Troubleshoot a Datatype Issue](#ex3)\n",
    "    * [Metadata Example 2: Compare a group of metadata files](#md2)\n",
    "        * [Exercise 4: Evaluate Values in a Subjects field](#ex4)\n",
    "    * [Metadata Example 3: Merge information from separate files](#md3)\n",
    "        * [Exercise 5: Other ways to merge](#ex5)\n",
    "    * [Bonus Example: Working with Dates](#md4)\n",
    "    * [Bonus Example: Find and remove duplicates](#md5)\n",
    "* [Resources](#res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workshop Plan <a name=\"wplan\"></a>\n",
    "\n",
    "We will start with a quick demo in using the jupyter notebook for running code cells and adding code to cells.\n",
    "\n",
    "Then we will walk through three examples of using Python/pandas with digital collections metadata files.  \n",
    "\n",
    "After each example there will be an exercise so you can try out working with the collections data.     \n",
    "\n",
    "\n",
    "----\n",
    "  \n",
    "**Intro, & using the jupyter notebook (10 mins)**\n",
    "    * Exercises 1 & 2: how to run code in notebook, and add new code to cells \n",
    "    \n",
    "**Example 1: Explore a dataset (12 mins)** \n",
    "    * Exercise 3: Troubleshoot a Datatype Issue\n",
    "    \n",
    "**Example 2: Compare a group of metadata files (12 mins)**\n",
    "    * Exercise 4: Evaluate Values in a Subject field\n",
    "    \n",
    "**Example 3: Merge info from separate files (12 mins)**\n",
    "    * Exercise 5 : Other Ways to Merge\n",
    "    \n",
    "**Wrap-up (5 mins)**\n",
    "    * Review resources, and info about installing python\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Jupyter Notebook <a name=\"usingjn\"></a>\n",
    "\n",
    "You can edit this notebook directly to run code cells and generate output, and add new code and text. In this section we'll go through basic commands to get familiar with working in the notebook. \n",
    "\n",
    "All paths in the notebook refer to locations within this project folder/git repository, so you can access example data and/or save output files within this project. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Run code cells <a name=\"ex1\"></a>\n",
    "\n",
    "Practice running Python code in the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cells and Markdown Cells\n",
    "\n",
    "All content in this notebook is located within individual cells, which you can identify by clicking on them. Clicking on a cell causes its borders to appear. \n",
    "\n",
    "Jupyter notebooks have two kinds of cells:   \n",
    "\n",
    "* **Code cells:** contain code that can be executed within the notebook. Code cells have an `In [ ]:` to the left of the cell. \n",
    "\n",
    "* **Markdown cells:** contain text providing explanation and context, usually about the code cells. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example code cell :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hashtags in a code cell indicate a comment -- informational text for a human to read, not to be executed as code\n",
    "\n",
    "print(\"here's an example code cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit Mode and Command Mode \n",
    "\n",
    "All cells in the notebook have two functional modes: \n",
    "* **Command mode:** used for navigating and moving cells = Blue cell border    \n",
    "* **Edit mode:** used for adding/editing content in cells = Green cell border\n",
    "\n",
    "To run a code cell, you need to put the cell into Edit mode by clicking on it.  \n",
    "(More info on Edit mode provided below. For now, just know that you need Edit mode to run a cell.)\n",
    "\n",
    "You can tell a cell is in Edit mode because the cell border turns green. \n",
    "\n",
    "If a cell has a blue border, it is in Command mode. To see the difference, click on the code cell above this Markdown cell.    \n",
    "The border should turn green = Edit mode. \n",
    "\n",
    "To switch back to Command mode, press the `Esc` key. The cell border will switch back to Blue = Command mode. \n",
    "\n",
    "**NOTE:** If you are not able to see Blue and Green, look for a cursor in the cell. If a cell is in Edit mode, you will see your cursor blinking in the cell. If there is no cursor blinking in the cell, it is in Command mode. \n",
    "\n",
    "Try switching the code cell below back and forth between Edit mode (green) and Command mode (blue) a few times to get used to how this works. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### another example code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more example code\n",
    "\n",
    "print(\"Toggle a code cell between Edit and Command modes using Esc and Enter keys.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to Run a Code Cell\n",
    "\n",
    "To run a code cell, click on it to switch the cell to Edit mode (green border). Then press `CTRL` + `Enter` to run the code. \n",
    "\n",
    "While the code runs, you'll see an `*` in the `In [ ]:` to the left of the cell. \n",
    "\n",
    "When the code completes, an integer will appear in the `In [ ]:` to the left of the cell.   \n",
    "\n",
    "If the code produced output, it will appear underneath the code cell.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try running this code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more example code\n",
    "\n",
    "print(\"Press CTRL + ENTER to run a code cell. If the code produces output, it will appear below the cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Add New Code to Cells <a name=\"ex2\"></a>\n",
    "\n",
    "For the pandas exercises in this notebook, you'll have the chance to add new code to cells to try out ideas.  \n",
    "This exercise walks through how to add code to a cell. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type or paste code into an existing cell\n",
    "\n",
    "For the exercises in this notebook, there will be empty code cells available to try out solutions. You can paste example code provided, or type your own. \n",
    "\n",
    "Look for the `In [ ]:` to the left of the cell, to make sure it's a code cell. \n",
    "\n",
    "\n",
    "Try out pasting this line of sample code into the empty code cell below and then running it: \n",
    "* Copy the block of text below starting from the ##, and ending with the )\n",
    "* Click on one of the empty code cells below, make sure the cell turns green for Edit mode, paste the copied block of code. \n",
    "* Then press `CTRL` + `ENTER` to run the code you pasted. \n",
    "\n",
    "```\n",
    "\n",
    "## comment \n",
    "print(\"here's an example of new code.\")\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the code cells below for the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  More Notebook Exercises: 'command palette', shortcuts, creating new cells <a name=\"mjn\"></a>\n",
    "\n",
    "Learn more about notebook commands, keyboard shortcuts, and creating new cells for Markdown and code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 'command palette' has all notebook actions and shortcuts\n",
    "\n",
    "In the command palette, you can search for any command, and run that action directly from the palette, as well as seeing the shortcut for that action if available. \n",
    "\n",
    "1. Press ``CTRL + SHIFT+ P`` to show the command palette. \n",
    "    * With the palette open, search for 'edit', to find the shortcut for `enter 'edit' mode`. Click on this action from the list. This cell will then switch into 'edit' mode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keyboard Shortcuts for Jupyter Notebook :\n",
    "\n",
    "* `CTRL` + `SHIFT`+ `P` : show 'command palette'\n",
    "* `esc` : command mode\n",
    "* `enter` : edit mode\n",
    "* `a` : insert cell above\n",
    "* `b` : insert cell below\n",
    "*  `SHIFT` + `enter`: run a code cell (or render a markdown cell)\n",
    "* `d d`: delete a cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit the text in a Markdown cell, execute (render) a Markdown cell\n",
    "\n",
    "* Switch this cell into 'edit mode'. \n",
    "* Add a bullet point below these lines of text and type something, for example: ``'DONE'``. (can copy/paste example below if easier!)\n",
    "* Then use `CTRL` + `Enter` to \"run\" the cell/render the markdown.  \n",
    "    * for example: `DONE`   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add new cells to notebook\n",
    "\n",
    "* With this cell in command mode (blue border), add a cell underneath it, then add some cells above the cells you added. \n",
    "    * press `b` to add a cell below an existing cell. \n",
    "    * You can keep pressing `b` to add more cells; it doesn't hurt anything to have empty cells in the notebook. \n",
    "    * press `a` to add a cell above an existing cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new Markdown cell, add some text\n",
    "\n",
    "create a Markdown cell: \n",
    "* click on one of the empty cells you created, or just create another one here. \n",
    "* A brand-new cell will be in command mode (blue cell border)  \n",
    "* if there's an `In [ ]:` to the left of the cell, this means it's a code cell. Any text you type into the cell will be treated as code. \n",
    "* To convert the cell to a Markdown cell, press `m` to switch the cell to markdown.  \n",
    "    * The `In [ ]:` to the left of the cell will disappear, indicating it is now a Markdown cell. Any test you type into the cell will now be treated as markdown. \n",
    "* If this did not work, make sure the cell is in command mode. Switch to Command mode by pressing `Esc`. The cell border will turn blue. \n",
    "\n",
    "add text in a Markdown cell: \n",
    "* Switch the cell to Edit mode by clicking inside it. \n",
    "* In the markdown cell, type a header, and then some regular text. For example: \n",
    "\n",
    "    ```\n",
    "    #### here's an example header  \n",
    "    and some regular paragraph text \n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use the markdown cell below for the exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(placeholder markdown cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute/render a markdown cell\n",
    "\n",
    "* As you did for the code cells, press `CTRL` + `Enter` to \"run\" the markdown cell/render the markdown that you just typed.  \n",
    "* the text will display as a formatted version, and the cell border will switch from green to blue. \n",
    "\n",
    "---\n",
    "---\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python/pandas examples with collections metadata files  <a name=\"ppe\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Example 1: Explore datasets with pandas<a name=\"md1\"></a>\n",
    "\n",
    "This example walks through getting oriented with using python/pandas for viewing and analysing descriptive metadata files.\n",
    "\n",
    "In this scenario we are working with a group of separate metadata files that have varied sets of inconsistently organized fields. We want to assess completeness of specific fields across the group as a whole. \n",
    "\n",
    "We will import metadata from csv and tsv files, figure out which fields are relevant for our assessment, and select those from the raw datasheets. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives in this example:\n",
    "\n",
    "* read a data file into a dataframe\n",
    "* create dataframes from differently delimited data\n",
    "* assess overall size and contents of the dataframe\n",
    "* view data in the dataframe\n",
    "* filter out irrelevant data\n",
    "* select relevant columns to include \n",
    "* identify basic datatype information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1:  Import libraries for Python\n",
    "\n",
    "Importing libraries loads them into memory so that Python can use them. \n",
    "\n",
    "Libraries provide specific methods for particular kinds of work. \n",
    "\n",
    "We are importing: \n",
    "* the pandas data analysis library\n",
    "* `os` for working with files and directories  \n",
    "* `matplotlib` for generating some basic graphs from data\n",
    "\n",
    "Setting `%matplotlib inline` allows plots to render within the notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas and os libraries \n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next: check that we are in the right place!!\n",
    "\n",
    "We'll do a couple quick checks to get oriented and make sure that we're in the right directory. \n",
    "\n",
    "This is not really necessary, because this notebook is located in/running from within the 'notebook_exercises' subfolder, so we already know that we will be running commands relative to that location, but it's useful to know how to take a look around to see where you are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd() outputs the current working directory, similar to pwd in bash\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir() with no parameter returns a list of the files and directories in the current working directory\n",
    "\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use os.listdir() plus a parameter to see what's in the exampleData subfolder\n",
    "\n",
    "os.listdir('./exampleData/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe from one of the metadata sheets\n",
    "\n",
    "A dataframe is a Python object with rows and columns that can be selected for running calculations and manipulating the data in a lot of ways. \n",
    "\n",
    "You can read many different data formats into a dataframe, including csv, tsv, and even excel sheets. \n",
    "\n",
    "The command below uses the variable name 'maps' for creating a dataframe using the pandas `read_csv` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe named 'maps' from an example metadata file \n",
    "\n",
    "maps=pd.read_csv(\"./exampleData/maps.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect a dataframe\n",
    "\n",
    "Next, we'll explore the maps dataframe with pandas attributes and methods, to get a sense of how large this datset is (how many rows and columns), what the column headers are and how many of them are empty, and what the datatypes are in each column. \n",
    "\n",
    "* shape\n",
    "* columns \n",
    "* info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape attribute displays the number of rows and columns for the dataframe, to get a sense of its overall size\n",
    "\n",
    "maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns attribute displays column labels\n",
    "\n",
    "maps.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the info method displays datatypes and numbers of values per column, and memory information\n",
    "\n",
    "maps.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datatypes in pandas\n",
    "\n",
    "the most common types are: \n",
    "\n",
    "object -   \n",
    "\n",
    "float64 -   \n",
    "\n",
    "int64 -   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting dataframe columns\n",
    "\n",
    "Since the columns listed above are not ordered in a logical way, it's hard to look for a particular column label in the output. \n",
    "\n",
    "However, dataframes can be sorted by rows, columns, or values. \n",
    "\n",
    "Below we'll sort the dataframe to display the column labels alphabetically, so that it's easier to check if this collection has fields we're interested in, such as Title, Usage Rights, Date, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe to order the output of column labels from the info() method\n",
    "\n",
    "maps.sort_index(axis=1).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View contents of a dataframe \n",
    "\n",
    "The head() and tail() methods in pandas display the first or last n rows of data. \n",
    "\n",
    "By default head or tails will display 5 rows; below we specify 3 to see fewer rows. \n",
    "\n",
    "Note that the column headers are no longer sorted alphabetically, because we did not apply the sort persistently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore another dataset\n",
    "\n",
    "Now we'll create another dataframe from a different collection. \n",
    "\n",
    "Using shape and info() to get a basic sense of the data, we can see that this data sheet has nearly twice as many column labels, and tons of empty fields.  \n",
    "\n",
    "We filter the dataset by getting rid of the empty columns, and selecting a set of columns to focus on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify delimiter for read_csv\n",
    "\n",
    "You can also use the read_csv function for other kinds of delimiters, such as tab-delimited for this metadata file. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in another example dataset as a separate dataframe. \n",
    "\n",
    "# use sep parameter to specify tab as delimiter\n",
    "\n",
    "rev=pd.read_csv(\"./exampleData/60001.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape to output number of rows and columns\n",
    "\n",
    "rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe to order the output of column labels from the info() method\n",
    "\n",
    "rev.sort_index(axis=1).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get rid of empty columns\n",
    "\n",
    "Many of these columns are empty, so we will exclude them. \n",
    "\n",
    "The \"inplace\" attribute will apply this change to the dataframe we are currently working with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty columns. Inplace attribute overwrites the working dataframe. \n",
    "\n",
    "rev.dropna(axis = 1, how ='all', inplace = True)\n",
    "\n",
    "# output updated dataframe\n",
    "\n",
    "rev.sort_index(axis=1).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Methods to Series in a Dataframe\n",
    "\n",
    "Columns in the dataframe are a python object called a Series. You can use some methods at the level of Series as well as at the dataframe level. \n",
    "\n",
    "For example, the head() and tail() methods can also be applied to series as well as the whole dataframe. \n",
    "\n",
    "Below we use the head method to look at a list of values in the Title field in our dataframe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first n rows of the Title column\n",
    "\n",
    "rev.Title.head(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chaining methods**\n",
    "\n",
    "You can chain methods together to apply another method to an object that has a method applied. \n",
    "\n",
    "Here we use the `sort_values` method to sort values in the Title series.  \n",
    "\n",
    "We use the 'ascending'=False parameter to sort reverse-alphabetically.  \n",
    "\n",
    "Then we apply the head() method to view the first 12 values of the sorted series. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first n values in the 'Title' series sorted alphabetically\n",
    "\n",
    "rev.Title.sort_values(ascending=False).head(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to Precisely Specify Locations in the Data\n",
    "\n",
    "The `.loc` method allows for selecting individual or multiple rows and columns.   \n",
    "\n",
    "Below we'll focus on the ``'Title','Date', 'Usage Rights', and 'filename'`` columns. \n",
    "\n",
    "We use a `:` to include all rows of the dataframe. \n",
    "\n",
    "We will use the tail() method to view the last few rows from this selection.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify multiple rows and columns by label with loc method \n",
    "\n",
    "rev.loc[:,['Title','Date', 'Usage Rights', 'filename']].tail(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply the same columns to the maps dataframe**\n",
    "\n",
    "Meanwhile, our maps dataframe is still available in working memory. \n",
    "\n",
    "Because the same column labels exist in the maps dataset, we can select out these columns from maps using .loc, the same way as we did with the rev dataframe above.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the same columns in the 'maps' dataframe\n",
    "# tail method displays the last n rows\n",
    "\n",
    "maps.loc[:,['Title','Date', 'Usage Rights', 'filename']].tail(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap of Metadata Example 1\n",
    "\n",
    "In this example, we got familiar with our collections metadata, and identified fields to assess.  \n",
    "\n",
    "In the next example, we will select out the relevant fields from a group of files, compile separate dataframes into a single dataframe, and compare fields across collections. \n",
    "\n",
    "\n",
    "**Summary of example:** \n",
    "\n",
    "* reading CSV and tab-delimited metadata sheets into dataframes\n",
    "* exploring a dataframe as a whole, series within a dataframe, values in rows and columns\n",
    "* filtering datasets by removing empty and irrelevant columns\n",
    "* selecting columns to include\n",
    "* working with multiple dataframes at once\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Troubleshoot a Datatype Issue <a name=\"ex3\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the three collections in this example is Collection Number 03883. The metadata filename is 03883.txt. \n",
    "\n",
    "\n",
    "\n",
    "Create a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./exampleData/03883.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis = 1, how ='all', inplace = True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Collection Number'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./exampleData/03883.txt',sep='\\t', dtype={'Collection Number':object})\n",
    "\n",
    "df['Collection Number'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Solution to Exercise 3: Troubleshoot a Datatype Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Example 2: Compare a group of metadata files <a name=\"md2\"></a>\n",
    "\n",
    "In Example 1, we identified fields we want to analyze in our group of collections: Title, Date, Usage Rights, and a few Subject fields. \n",
    "\n",
    "In this example, we will select out the relevant fields from a group of datasheets by creating a variable to store the set of columns we're interested in.  \n",
    "\n",
    "Then we will concatenate metadata from the separate collections into a single dataframe that makes it easier to compare completeness of metadata across the group as a whole. \n",
    "\n",
    "We will generate basic graphs to show comparisons between the collections. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives in this example:   \n",
    "\n",
    "* Use a variable for storing a list\n",
    "* Select columns on import with `usecols` parameter\n",
    "* Create a new column\n",
    "* Use `.groupby` to organize data\n",
    "* Generate plots for visual comparisons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use a variable to store the column names we want\n",
    "\n",
    "We create a variable 'collabels' to hold the list of the Column labels that we will then select out from each datasheet. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable for column labels\n",
    "\n",
    "collabels=['Title','Date','Usage Rights', 'Subject Geographic', 'Subject Name' , 'Subject Topical']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select relevant columns and create a new column with Collection Names\n",
    "\n",
    "Now we can create a dataframe from each metadata sheet, including only the relevant Columns. \n",
    "\n",
    "We also create a new column in each dataframe that contains a simple collection name. We'll use these collection names when we group the metadata together into a single dataframe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the same datasheets from the last example\n",
    "\n",
    "# create a new column in each dataframe that contain a short Collection Name value\n",
    "\n",
    "maps=pd.read_csv(\"./exampleData/maps.csv\", usecols=collabels)\n",
    "maps['colname'] ='Civil War Maps'\n",
    "\n",
    "rev=pd.read_csv(\"./exampleData/60001.txt\", usecols=collabels, sep='\\t')\n",
    "rev['colname'] ='Revolution Photographs'\n",
    "\n",
    "rmb=pd.read_csv(\"./exampleData/03883.txt\", sep='\\t', usecols=collabels)\n",
    "rmb['colname'] ='Roy M Brown Papers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check our new dataframes \n",
    "\n",
    "Again use info() to see the value counts and datatypes in each Column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show info for updated dataframes \n",
    "\n",
    "maps.sort_index(axis=1).info()\n",
    "print('\\n')\n",
    "\n",
    "rev.sort_index(axis=1).info()\n",
    "print('\\n')\n",
    "\n",
    "rmb.sort_index(axis=1).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate into single dataframe\n",
    "\n",
    "We create a new dataframe 'collstack', by concatenating the maps, rmb, and rev dataframes. \n",
    "\n",
    "Then we'll check that everything looks ok by looking at shape and info() for collstack. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate dataframes into a single dataframe\n",
    "\n",
    "collstack = pd.concat([maps, rmb, rev], axis=0, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collstack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collstack.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group the data by the Collection Names we created\n",
    "\n",
    "Now we can group the data by the Collection Names, and select fields to compare across the collections. \n",
    "\n",
    "The count() method counts the values in the Title and Usage Rights field for each collection. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by collection name, counting values in Title and Usage Rights columns\n",
    "\n",
    "collstack.groupby('colname')['Title', 'Usage Rights'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Plots to Represent Comparisons Visually\n",
    "\n",
    "Next we'll generate some very basic plots to demonstrate working with pandas and matplotlib. \n",
    "\n",
    "Visualization is obviously a huge area in itself! These are not in any way impressive visualizations, but are just meant to give a little sense of pandas' flexible graphing capabilities. \n",
    "\n",
    "For example, by just adding `.plot(kind='bar')` to the code from the previous cell, we generate a bar graph of the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bar graph for the Title/Usage Rights comparison\n",
    "\n",
    "collstack.groupby('colname')['Title', 'Usage Rights'].count().plot(kind='bar', figsize=(8,6),width=0.8, )\n",
    "plt.ylabel('Count of items')\n",
    "plt.xlabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate Subjects fields across the collections \n",
    "\n",
    "We can include different column labels to focus on the subject fields instead, and plot the result. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collstack.groupby('colname')['Title', 'Subject Geographic', 'Subject Name', 'Subject Topical'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a horizontal bar graph for the Subjects comparison\n",
    "\n",
    "collstack.groupby('colname')['Title', 'Subject Geographic', 'Subject Name', 'Subject Topical'].count().plot(kind='barh', figsize=(8,6), width=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with plot types and subsets of data\n",
    "\n",
    "By changing the value of the `kind=` parameter for `.plot`, we can experiment with different plot types to see which is best suited to a comparison. \n",
    "\n",
    "We can also use pandas methods to select a particular range of data to focus on in a plot. \n",
    "\n",
    "In this example, we focus on the people represented in the maps collection. We can sort the value counts in ascending order to produce a legible curve. \n",
    "\n",
    "If we want to focus on a smaller set within the group, we can use head() to focus on the most-represented names.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a horizontal bar graph for the Subjects Name counts in maps collection \n",
    "\n",
    "maps.groupby(['Subject Name']).Title.count().sort_values(ascending=False).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the barh graph to top 5 values\n",
    "\n",
    "maps.groupby(['Subject Name']).Title.count().sort_values(ascending=False).head().plot(kind='barh', figsize=(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Represent the same data as a pie plot\n",
    "\n",
    "Again changing the `kind=` parameter for `.plot` generates a different view of the same selection from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pie plot for the Subjects Name counts in maps collection \n",
    "\n",
    "maps.groupby(['Subject Name']).Title.count().sort_values(ascending=False).head().plot(kind='pie', figsize=(8,8),startangle=180)\n",
    "plt.ylabel('')\n",
    "#plt.title(\"Most Common Subject Names in Maps Collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other ways to reframe a selection\n",
    "\n",
    "Unsurprisingly, Jeremy Francis Gilmer is the most common name in the Gilmer maps collection. \n",
    "\n",
    "If we wanted to create a plot that excludes this obvious result, we could create a variable to select value counts that focus on a given range that we're more interested in. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group maps by Subject Name, counting Titles, view top n\n",
    "\n",
    "maps.groupby(['Subject Name']).Title.count().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable that specifies a range to examine\n",
    "# exclude the most-common heading to focus on the next seven values\n",
    "# create a pie plot from result\n",
    "\n",
    "subcounts=maps['Subject Name'].value_counts()\n",
    "\n",
    "totals=subcounts[(subcounts <= 103) & (subcounts>2)]\n",
    "\n",
    "totals.sort_values(ascending=False).plot(kind='pie', figsize=(8,8),startangle=90)\n",
    "plt.ylabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap of Example 2 \n",
    "\n",
    "In this example, we selected relevant fields from across separate datasheets and combined the data for comparison, using simple plots to assess collections visually. \n",
    "\n",
    "**summary of this example:**\n",
    "\n",
    "* use a variable to select a set of columns from multiple datasets \n",
    "* create a new column and add data\n",
    "* concatenate separate data into a single dataframe\n",
    "* organize datasets for comparison with groupby \n",
    "* compare datasets visually using basic graphs\n",
    "* explore different graph formats according to data attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Evaluate values in a subject field in the maps collection<a name=\"ex4\"></a>\n",
    "\n",
    "\n",
    "In this exercise, we will take a closer look at values in the 'Subject Topical' field in the Maps collection. \n",
    "\n",
    "Based on the output below from maps.info(), it looks like the Subject Topical field is fairly complete in this collection. \n",
    "\n",
    "```\n",
    "maps.info()\n",
    "```\n",
    "\n",
    "```\n",
    "RangeIndex: 161 entries, 0 to 160\n",
    "Data columns (total 7 columns):\n",
    "Title                 161 non-null object\n",
    "Date                  161 non-null object\n",
    "Subject Topical       161 non-null object\n",
    "Subject Name          161 non-null object\n",
    "Subject Geographic    161 non-null object\n",
    "Usage Rights          0 non-null float64\n",
    "colname               161 non-null object\n",
    "```\n",
    "Try using the describe() method to get more details about the values represented within the 'Subject Topical' field. \n",
    "\n",
    "Would plotting the maps titles according to 'Subject Topical' fields assigned to them make an interesting graph? \n",
    "\n",
    "**To answer this question, add and run code into the empty code cells below to:**  \n",
    "\n",
    "* check the output from describe() for the maps dataframe\n",
    "* and to generate a plot for numbers of maps titles grouped by Subject Topical. \n",
    "\n",
    "---\n",
    "\n",
    "Here is code that you can paste into the empty code cells, (or feel free to type in the code!)\n",
    "\n",
    "1. check the output from describe() for the maps dataframe\n",
    "\n",
    "```\n",
    "\n",
    "# use describe() to evaluate the contents of the 'Subject Topical' field\n",
    "maps['Subject Topical'].describe()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "2. generate a plot for numbers of maps titles grouped by Subject Topical. \n",
    "\n",
    "```\n",
    "\n",
    "# generate a plot for the distribution of Subject Topical field across titles\n",
    "maps.groupby(['Subject Topical']).Title.count().plot(kind='barh',color=['grey'])\n",
    "plt.xlabel('item count')\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "For reference, the solution is also demonstrated in the next set of cells below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use these empty code cells for the exercise: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution to Exercise 4: Evaluate Subjects data in a collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from `describe()` shows that although every item in this collection has a Subject Topical field, it is all the same value. \n",
    "\n",
    "So, plotting the Title counts for the Subject Topical field does not make a very interesting plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use describe() to evaluate the contents of the 'Subject Topical' field\n",
    "\n",
    "maps['Subject Topical'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a plot for the distribution of Subject Topical field across titles\n",
    "\n",
    "maps.groupby(['Subject Topical']).Title.count().plot(kind='barh',color=['grey'])\n",
    "plt.xlabel('item count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Example 3: Merge information from separate files <a name=\"md3\"></a>\n",
    "\n",
    "Another useful feature of pandas is that it allows you to do SQL-like joins with datasheets.  \n",
    "\n",
    "In this exercise, we will create a merged dataframe from descriptive metadata and file sizes information in separate datasets. \n",
    "\n",
    "We will rename columns in the descriptive metadata dataframe to merge based on columns in our filesizes datasheets.  \n",
    "(It's also possible to specify the columns to merge separately for the left and right dataframes if they are not named the same!)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives in this example:  \n",
    "\n",
    "* Review of removing empty columns\n",
    "* Review of datatypes and potential errors, specifying datatypes for columns\n",
    "* Rename columns \n",
    "* Merge dataframes \n",
    "* Write a dataframe to a csv output file or other format \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the import statement below and run this cell if your notebook was reset and you need the libraries again\n",
    "\n",
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of collections metadata in this example\n",
    "\n",
    "In this example, we have three separate datasheets about various files from a single collection. We are going to combine them into one dataframe by merging on filenames. \n",
    "\n",
    "* descriptive metadata about the items\n",
    "* technical metadata about the access files\n",
    "* technical metadata about the 'master' files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe for descriptive metadata\n",
    "\n",
    "As in previous examples, we will create a dataframe and check out its overall size, columns, and value counts.\n",
    "\n",
    "Then we'll drop the empty columns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in collections metadata file as 'metadata' dataframe\n",
    "metadata=pd.read_csv(\"./exampleData/03823_metadata.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use shape attribute to summarize rows and columns.\n",
    "\n",
    "print(metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the info method to see column names and item counts in each column\n",
    "\n",
    "metadata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix datatype for collection number \n",
    "\n",
    "As in our exercise above, 'Collection Number' is getting cast as an `int64` datatype. \n",
    "\n",
    "We can fix this by re-creating our dataframe, specifying `object` datatype for this column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['Collection Number'].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata=pd.read_csv(\"./exampleData/03823_metadata.txt\", sep='\\t', dtype={'Collection Number':object})\n",
    "\n",
    "metadata['Collection Number'].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the empty columns using dropna\n",
    "\n",
    "# and re-check the column names and item counts by re-running the info method on the reshaped dataset.\n",
    "\n",
    "metadata.dropna(axis = 1, how ='all', inplace = True)\n",
    "\n",
    "metadata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify which field to merge with Access Files\n",
    "\n",
    "We will take a look at a few rows to see which field has the filenames we are matching to access files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the head method to see the first n rows\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the second dataframe with the access files datasheet\n",
    "\n",
    "accfiles=pd.read_csv(\"./exampleData/03823_access_images.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accfiles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the second dataframe with the access files datasheet\n",
    "\n",
    "accfiles=pd.read_csv(\"./exampleData/03823_access_images.csv\", usecols=['Name','Full Path', 'Size'])\n",
    "\n",
    "accfiles.rename(columns={'Name':'AccessName', 'Full Path':'AccessFilePath', 'Size' : 'AccessFileSize'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use shape and info to take a look at the accfiles dataframe.\n",
    "print(accfiles.shape) \n",
    "\n",
    "accfiles.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the head method to see the first n rows of a column\n",
    "\n",
    "accfiles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename a column \n",
    "\n",
    "metadata.rename(columns={'Object file name':'AccessName'}, inplace=True)\n",
    "metadata.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join access files data onto the metadata dataframe\n",
    "# and view info for the new, merged dataframe\n",
    "\n",
    "combined = pd.merge(metadata, accfiles,on='AccessName', how='left')\n",
    "\n",
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.AccessFileSize.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['AccessSizeNum'] = combined.AccessFileSize.apply(lambda x: x.replace(' Bytes',''))\n",
    "\n",
    "combined=combined.astype({'AccessSizeNum':'int64'})\n",
    "\n",
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the merged dataframe to a new csv\n",
    "\n",
    "combined.to_csv('./output/accessfilesizes_metadata_03823.csv', index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a third dataframe with the masters files datasheet\n",
    "\n",
    "masters=pd.read_csv(\"./exampleData/03823_masters.csv\", usecols=['Name','Full Path', 'Size'])\n",
    "\n",
    "masters.rename(columns={'Name':'MastersName', 'Full Path':'MasterFilePath', 'Size' : 'MasterFileSize'}, inplace=True)\n",
    "\n",
    "masters['MasterSizeNum'] = masters.MasterFileSize.apply(lambda x: x.replace(' Bytes',''))\n",
    "\n",
    "masters=masters.astype({'MasterSizeNum':'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masters.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masters.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.rename(columns={'filename':'MastersName'}, inplace=True)\n",
    "\n",
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all3 = pd.merge(combined, masters,on='MastersName', how='left')\n",
    "\n",
    "all3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all3.loc[:,['Collection Number','Object', 'MastersName', 'AccessName', 'AccessSizeNum','MasterSizeNum']].head(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercise 5: Other ways to merge <a name=\"ex5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the tail method to see the last n rows of a column\n",
    "accfiles.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use python string method to count instances of 'icon'\n",
    "\n",
    "accfiles['AccessName'].str.count(\"icon\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Solution to Exercise 5: Other ways to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Example: Datatypes and Working with Dates<a name=\"md4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use 'to_datetime' to convert datatype in Dates column\n",
    "\n",
    "In this example, we will go back to our rev dataframe and examine the datatype for the Dates field.  \n",
    "\n",
    "Notice the format of the values in the 'Date' column. We can also see in the info() output that the datatype for 'Date' is currently 'object'. Right now python is viewing these dates as just strings, which limits what we can do with them. \n",
    "\n",
    "We can create a new column in the dataframe, using the `to_datetime` method to convert the 'Date' values to datatype 'datetime', which then has a lot of capabilities available to it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev.Date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the current datatype and values information for the `Date` column in the rev dataframe\n",
    "\n",
    "rev.Date.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'datesformat', with the values from the Date column \n",
    "# Use to_datetime to convert the 'Date' values to the datetime datatype\n",
    "\n",
    "rev['datesformat']=pd.to_datetime(rev['Date'])\n",
    "\n",
    "rev.datesformat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the current datatype and values information for the new `datesformat` column in the rev dataframe\n",
    "\n",
    "rev.datesformat.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the dataframe with new column added\n",
    "\n",
    "Note that the new column will be added at the end of the dataframe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the columns and dtypes in the rev dataframe\n",
    "\n",
    "rev.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Example: Find and remove duplicates <a name=\"md5\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll=pd.read_csv('./exampleData/coll_dupes_example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll=pd.read_csv('./exampleData/coll_dupes_example.csv', usecols=['Collection Number','Object', 'filename', 'Date created', 'Date modified'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll.Object.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates with drop_duplicates method\n",
    "\n",
    "deduped= coll.drop_duplicates(subset= 'Object', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "31+39125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes_all=coll.loc[coll.Object.duplicated(keep=False), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dupes_all.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes_all.sort_values(['Collection Number','Object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write duplicates dataframe to a csv, sorted by Collection number then by Object field\n",
    "\n",
    "dupes_all.sort_values(['Collection Number','Object']).to_csv('./output/coll_dupes_all_sorted.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can look at new datasheet as a dataframe, or open it in an external spreadsheet program\n",
    "\n",
    "da=pd.read_csv('./output/coll_dupes_all_sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources <a name=\"res\"></a>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
