{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Python Tools for Metadata Assessment: 55-minute workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome\n",
    "\n",
    "Welcome to the workshop! This is meant to be a a fun and beginner-friendly introduction to a few useful Python tools, in the context of exploring and manipulating tabular metadata for digital collections.   \n",
    "\n",
    "In this session, we will focus on some basic functions of Python's pandas data analysis library. We will use pandas for exploring, filtering, reshaping, and merging datasets. \n",
    "\n",
    "This notebook provides code that you can execute to see results and generate outputs in the notebook itself, as well as explanations for the examples and exercises we'll be working through together. \n",
    "\n",
    "At the end of the notebook, there is a bonus example about dealing with duplicates, and a list of recommended resources for further exploration on your own. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "* [Workshop Plan](#wplan)\n",
    "* [Introduction](#intro)\n",
    "* [Using this Jupyter Notebook](#usingjn)\n",
    "    * [Exercise 1: Modify this notebook](#ex1)\n",
    "    * [Exercise 2: Run code and markdown in cells](#ex2)\n",
    "* [Example 1: Explore a dataset](#md1)\n",
    "    * [Exercise 3: Try out pandas methods](#ex3)\n",
    "* [Example 2: Compare a group of metadata files](#md2)\n",
    "    * [Exercise 4: Evaluate subjects data in a collection](#ex4)\n",
    "* [Example 3: Merge information from separate files](#md3)\n",
    "    * [Exercise 5: Other ways to merge](#ex5)\n",
    "* [Bonus Example: Find and remove duplicates](#md4)\n",
    "* [Resources](#res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workshop Plan <a name=\"wplan\"></a>\n",
    "\n",
    "We will start with a quick demo in using the jupyter notebook and a couple exercises to get familiar with notebook commands. \n",
    "\n",
    "Then we will walk through three examples of using Python/pandas with digital collections metadata files.  \n",
    "After each example there will be an exercise you can try out on your own.  \n",
    "\n",
    "\n",
    "----\n",
    "  \n",
    "**Intro, & using the jupyter notebook (10 mins)**\n",
    "    * Exercises 1 & 2: how to add cells, execute code and markdown cells\n",
    "    \n",
    "**Example 1: Explore a dataset (12 mins)** \n",
    "    * Exercise 3: Evaluate subjects data from a collection\n",
    "    \n",
    "**Example 2: compare a group of metadata files (12 mins)**\n",
    "    * Exercise 4: \n",
    "    \n",
    "**Example 3: Merge info from separate files (12 mins)**\n",
    "    * Exercise 5 : other merges  \n",
    "    \n",
    "**Wrap-up (5 mins)**\n",
    "    * review resources, and info about installing python\n",
    "\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Python and pandas<a name=\"intro\"></a>\n",
    "(basic info about Python)\n",
    "\n",
    "(basic info about Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using this Jupyter Notebook <a name=\"usingjn\"></a>\n",
    "\n",
    "You can edit the notebook to run code cells and generate output, and/or to add markdown cells.  \n",
    "\n",
    "All paths in the notebook refer to locations within the repository, to access example data and/or save output files. \n",
    "\n",
    "### Keyboard Shortcuts for Jupyter Notebook :\n",
    "\n",
    "* `CTRL` + `SHIFT`+ `P` : show 'command palette'\n",
    "* `esc` : command mode\n",
    "* `enter` : edit mode\n",
    "* `a` : insert cell above\n",
    "* `b` : insert cell below\n",
    "*  `SHIFT` + `enter`: run a code cell (or render a markdown cell)\n",
    "* `d d`: delete a cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercise 1: Modify this Notebook<a name=\"ex1\"></a>\n",
    "\n",
    "Follow the instructions below to try out some of the jupyter keyboard shortcuts and get familiar with working in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**check out the 'command palette' to see all notebook actions and shortcuts**\n",
    "\n",
    "From the command palette, you can search for any command, and run that action directly from the palette, as well as seeing the shortcut for that action if available. \n",
    "\n",
    "1. Press ``CTRL + SHIFT+ P`` to show the command palette. \n",
    "    * With the palette open, search for 'edit', to find the shortcut for `enter 'edit' mode`. Click on this action from the list. This cell will then switch into 'edit' mode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use shortcuts to switch between edit and command mode**\n",
    "\n",
    "Edit mode: used for adding/editing content in cells = Blue cell border\n",
    "\n",
    "Command mode: used for navigating and modifying cells = Green cell border    \n",
    "\n",
    "* Double-click in this cell to switch the cell into 'Edit mode.' \n",
    "* When you double click inside the cell, the cell border will change from blue to green, and the markdown will switch from rendered to markup text.\n",
    "* Press `Esc` to switch back to 'command' mode. The cell border switches back to blue and you can use navigation commands (such as adding cells below/above, switching from code/markdown.)  \n",
    "* Practice switching back and forth between edit/command on a few cells. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edit the text in a Markdown cell, execute (render) a Markdown cell**\n",
    "\n",
    "* Switch this cell into 'edit mode'. \n",
    "* Add a bullet point below these lines of text and type something, for example: ``'DONE'``. (can copy/paste example below if easier!)\n",
    "* Then use `CTRL` + `Enter` to \"run\" the cell/render the markdown.  \n",
    "    * for example: `DONE`   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add more cells**\n",
    "\n",
    "* With this cell in command mode (blue border), add a cell underneath it, then add some cells above the cells you added. \n",
    "    * press `b` to add a cell below an existing cell. \n",
    "    * You can keep pressing `b` to add more cells; it doesn't hurt anything to have empty cells in the notebook. \n",
    "    * press `a` to add a cell above an existing cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Add and run code and Markdown in cells <a name=\"ex2\"></a>\n",
    "\n",
    "Practice with creating cells, switching cells from code to Markdown, adding content to cells and running them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a Markdown cell, add some text**\n",
    "\n",
    "create a Markdown cell: \n",
    "* click on one of the empty cells you created in Exercise 1, or just create another one here. \n",
    "* A brand-new cell will be in command mode (blue cell border)  \n",
    "* if there's an `In [ ]:` to the left of the cell, this means it's a code cell. Any text you type into the cell will be treated as code. \n",
    "* To convert the cell to a Markdown cell, press `m` to switch the cell to markdown.  \n",
    "    * The `In [ ]:` to the left of the cell will disappear, indicating it is now a Markdown cell. Any test you type into the cell will now be treated as markdown. \n",
    "* If this did not work, make sure the cell is in command mode. Switch to Command mode by pressing `Esc`. The cell border will turn blue. \n",
    "\n",
    "add text in a Markdown cell: \n",
    "* Switch the cell to Edit mode by clicking inside it. \n",
    "* In the markdown cell, type a header, and then some regular text. For example: \n",
    "\n",
    "    ```\n",
    "    #### here's an example header  \n",
    "    and some regular paragraph text \n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### here's an example header  \n",
    "and some regular paragraph text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute/render a markdown cell**\n",
    "\n",
    "* As you did in exercise 1, press `CTRL` + `Enter` to \"run\" the markdown cell/render the markdown that you just typed.  \n",
    "* the text will display as a formatted version, and the cell border will switch from green to blue. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add code to a code cell**\n",
    "\n",
    "Work with a code cell: \n",
    "* Click on one of the empty cells you have created, or just create a new one here. \n",
    "* Look for the `In [ ]:` to the left of the cell, to make sure it's a code cell. \n",
    "* if there's no  `In [ ]:` to the left of the cell, switch into Command mode and convert the cell to Code by pressing `y`. \n",
    "* Switch the cell back to Edit mode by clicking inside it. The cell border will turn green. \n",
    "\n",
    "Add some code: \n",
    "* Type a line of simple python code. For example: \n",
    "\n",
    "     ```\n",
    "     print(\"here's a line of python code output.\")\n",
    "     ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the code cell.**\n",
    "\n",
    "* As you did with the markdown cells, press `CTRL` + `Enter` to run the cell and execute the code in it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## note that in a code cell, hashtags indicate a comment, not a header as in a markdown cell\n",
    "\n",
    "print(\"here's a line of python code output.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Example 1: Explore a Dataset with pandas<a name=\"md1\"></a>\n",
    "\n",
    "This example walks through getting oriented with using python/pandas for viewing and analysing descriptive metadata files.\n",
    "\n",
    "In this scenario we are working with a small group of metadata files that have varied sets of inconsistently organized fields.   \n",
    "\n",
    "We will import metadata from csv and tsv files, exclude empty and/or irrelevant fields from our dataframes, and identify a few relevant fields to focus on for assessment, selecting the same set of fields from each collection. \n",
    "\n",
    "**Learning objectives in this example:**\n",
    "\n",
    "* reading a data file into a dataframe\n",
    "* creating dataframes with differently delimited data\n",
    "* assessing overall size and contents of the dataframe\n",
    "* selecting relevant columns to include for a task\n",
    "* identifying and changing datatypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries for Python\n",
    "\n",
    "Importing libraries loads them into memory so that Python can use them. \n",
    "\n",
    "Libraries provide specific methods for particular kinds of work. \n",
    "\n",
    "We are importing: \n",
    "* the pandas data analysis library\n",
    "* `os` for working with files and directories  \n",
    "* `matplotlib` for generating some basic graphs from data\n",
    "\n",
    "Setting `%matplotlib inline` allows plots to render within the notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas and os libraries \n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next: check that we are in the right place!!\n",
    "\n",
    "We'll do a couple quick checks to get oriented and make sure that we're in the right directory. \n",
    "\n",
    "This is not really necessary, because this notebook is located in/running from within the 'notebook_exercises' subfolder, so we already know that we will be running commands relative to that location, but it's always nice to take a look around to see where you are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd() outputs the current working directory, similar to pwd in bash\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir() with no parameter returns a list of the files and directories in the current working directory\n",
    "\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use os.listdir() plus a parameter to see what's in the exampleData subfolder\n",
    "\n",
    "os.listdir('./exampleData/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe from example datasets\n",
    "\n",
    "A dataframe is a Python object with rows and columns that can be selected for running calculations and manipulating the data in a lot of ways. \n",
    "\n",
    "You can read many different data formats into a dataframe, including csv, tsv, and even excel sheets. \n",
    "\n",
    "The command below uses the variable name 'maps' for creating a dataframe using the pandas `read_csv` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe: 'maps' from the example datasheet \n",
    "\n",
    "maps=pd.read_csv(\"./exampleData/maps.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect a dataframe\n",
    "\n",
    "Next, we'll explore the maps dataframe with pandas attributes and methods, to get a sense of how large this datset is (how many rows and columns), what the column headers are and how many of them are empty, and what the datatypes are in each column. \n",
    "\n",
    "* shape\n",
    "* columns \n",
    "* info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape attribute displays the number of rows and columns for the dataframe, to get a sense of its overall size\n",
    "\n",
    "maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns attribute displays column labels\n",
    "\n",
    "maps.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the info method displays datatypes and numbers of values per column, and memory information\n",
    "\n",
    "maps.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sorting dataframe columns**\n",
    "\n",
    "Since the columns listed above are not ordered in a logical way, it's hard to look for a particular column label in the output. \n",
    "\n",
    "Dateaframes can be sorted by rows, columns, or values to present the data according to the order we specify. \n",
    "\n",
    "Below we'll display the column labels sorted alphabetically, which makes it easy to check if this collection has fields named  Title, Usage Rights, Date, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe to order the output of column labels from the info() method\n",
    "\n",
    "maps.sort_index(axis=1).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View contents of the dataframe \n",
    "\n",
    "The head() and tail() methods in pandas display the first or last n rows of data. \n",
    "\n",
    "By default head or tails will display 5 rows; below we specify 3 to see fewer rows. \n",
    "\n",
    "Note that the column headers are no longer sorted alphabetically, because we did not apply the sort persistently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore a second dataset\n",
    "\n",
    "You can also use the read_csv function for other kinds of delimiters. For example, you can specify tab-delimited as with the metadata file below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in another example dataset as a separate dataframe. \n",
    "# use sep parameter to specify tab as delimiter\n",
    "\n",
    "rev=pd.read_csv(\"./exampleData/60001.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View size and columns information for second dataset**\n",
    "\n",
    "We'll again use shape and info() to get a basic sense of the second dataset. \n",
    "\n",
    "We can see that this data sheet has nearly twice as many column labels, and tons of empty fields.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev.sort_index(axis=1).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get rid of empty columns\n",
    "\n",
    "Many of these columns are empty, so we will exclude them. \n",
    "\n",
    "Use the inplace attribute to apply this change to the dataframe we are currently working with.\n",
    "\n",
    "Then check the columns again; our data is now more manageable. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty columns. Inplace attribute overwrites the working dataframe. \n",
    "rev.dropna(axis = 1, how ='all', inplace = True)\n",
    "\n",
    "# output updated dataframe\n",
    "rev.sort_index(axis=1).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other ways to view and select data\n",
    "\n",
    "The head() and tail() methods can also be applied to series as well as the whole dataframe. \n",
    "\n",
    "Use the head method to list the first twelve values in the Title field in our dataframe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first 12 rows of the Title column\n",
    "\n",
    "rev.Title.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chaining methods**\n",
    "\n",
    "You can chain methods together to apply another method to an object that has a method applied. \n",
    "\n",
    "For example, we can use the sort_values method to sort the Title series reverse-alphabetically (via the 'ascending' parameter set to false), then apply the head() method to view th first 12 values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first 12 values in the 'Title' series sorted alphabetically\n",
    "\n",
    "rev.Title.sort_values(ascending=False).head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specifying rows and columns**\n",
    "\n",
    "The .loc method allows for selecting individual and multiple rows and columns. Below we'll focus on the ``'Title','Date', 'Usage Rights', and 'filename'`` columns, including all rows of the dataframe. \n",
    "\n",
    "We will use the tail() method to view the last n rows in these columns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify multiple rows and columns by label with loc method \n",
    "\n",
    "rev.loc[:,['Title','Date', 'Usage Rights', 'filename']].tail(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with dates \n",
    "\n",
    "Notice the format of the values in the 'Date' column above. Also, remember from the info() output that the datatype for 'Date' is currently 'object'. Right now python is viewing these dates as just strings, which limits what we can do with them. \n",
    "\n",
    "We can create a new column in the dataframe, using the `to_datetime` method to convert the 'Date' values to datatype 'datetime', which then has a lot of capabilities available to it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the current datatype and values information for the `Date` column in the rev dataframe\n",
    "\n",
    "rev.Date.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'datesformat', with the values from the Date column \n",
    "# Use to_datetime to convert the 'Date' values to the datetime datatype\n",
    "\n",
    "rev['datesformat']=pd.to_datetime(rev['Date'])\n",
    "\n",
    "rev.datesformat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the current datatype and values information for the new `datesformat` column in the rev dataframe\n",
    "\n",
    "rev.datesformat.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspect the dataframe with new column added**\n",
    "\n",
    "Note that the new column will be added at the end of the dataframe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the columns and dtypes in the rev dataframe\n",
    "\n",
    "rev.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply the same columns to the maps dataframe**\n",
    "\n",
    "Meanwhile, our maps dataframe is still available in working memory. \n",
    "\n",
    "Because the same column labels exist in the maps dataset, we can select out these columns from maps using .loc, the same way as we did with rev above.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the same columns in the 'maps' dataframe\n",
    "# tail method displays the last n rows\n",
    "\n",
    "maps.loc[:,['Title','Date', 'Usage Rights', 'filename']].tail(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap of Metadata Example 1\n",
    "\n",
    "this example covered the following: \n",
    "\n",
    "* read data of different formats into a dataframe\n",
    "* explore a dataframe as a whole, series within a dataframe, values in rows and columns\n",
    "* filter datasets by sorting, selecting, and dropping columns\n",
    "* work with multiple dataframes at once\n",
    "* create a new column in a dataframe \n",
    "* format dates by converting column datatype with to_datetime\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: nameofexercise <a name=\"ex3\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out some of the methods demonstrated above, with an example datasheet in this repository. \n",
    "\n",
    "Use the standard `df` variable name to create a dataframe from the '60001.txt' file.   \n",
    "\n",
    "Note that this metadata file is not a csv, so you will need to specify the delimiter. \n",
    "\n",
    "The syntax for this is:\n",
    "```\n",
    "df=pd.read_csv('./exampleData/03883.txt', sep='\\t')\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./exampleData/03883.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the shape and column labels of the dataframe. Then inspect the Title column, sorted alphabetically. \n",
    "\n",
    "\n",
    "```\n",
    "df.shape  \n",
    "```\n",
    "```\n",
    "df.info()  \n",
    "```\n",
    "```\n",
    "df.Title.sort_values().head(12)  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Title.sort_values().head(12)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Solution to Exercise 3: nameofexercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Example 2: Compare a group of metadata files <a name=\"md2\"></a>\n",
    "\n",
    "This example continues where Example 1 left off. Having identified a set of fields to analyze in our group of collections, we will create new dataframes from the raw datasheets. This time we will include only the set of relevant columns from a group of collections. \n",
    "\n",
    "We will then concatenate the new dataframes into a single compiled dataset that makes it easy to compare completeness of metadata across the group as a whole. \n",
    "\n",
    "We will generate basic graphs to show comparisons between the collections. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable to store the column labels we want to select from each dataset\n",
    "\n",
    "coltitles=['Title','Date','Usage Rights', 'Subject Geographic', 'Subject Name' , 'Subject Topical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the same datasheets from the last example\n",
    "# create a new column in each dataframe that contain a short Collection Name value\n",
    "\n",
    "maps=pd.read_csv(\"./exampleData/maps.csv\", usecols=coltitles)\n",
    "maps['colname'] ='Civil War Maps'\n",
    "\n",
    "rev=pd.read_csv(\"./exampleData/60001.txt\", usecols=coltitles, sep='\\t')\n",
    "rev['colname'] ='Revolution Photographs'\n",
    "\n",
    "rmb=pd.read_csv(\"./exampleData/03883.txt\", sep='\\t', usecols=coltitles)\n",
    "rmb['colname'] ='Roy M Brown Papers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show info for updated dataframes \n",
    "\n",
    "maps.sort_index(axis=1).info()\n",
    "print('\\n')\n",
    "\n",
    "rev.sort_index(axis=1).info()\n",
    "print('\\n')\n",
    "\n",
    "rmb.sort_index(axis=1).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate dataframes into a single dataframe\n",
    "\n",
    "collstack = pd.concat([maps, rmb, rev], axis=0, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collstack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collstack.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collstack.groupby('colname')['Title', 'Usage Rights'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collstack.groupby('colname')['Title', 'Usage Rights'].count().plot(kind='bar', figsize=(8,6),width=0.8, )\n",
    "plt.ylabel('Count of items')\n",
    "plt.xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collstack.groupby('colname')['Title', 'Subject Geographic', 'Subject Name', 'Subject Topical'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collstack.groupby('colname')['Title', 'Subject Geographic', 'Subject Name', 'Subject Topical'].count().plot(kind='barh', figsize=(8,6), width=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maps.groupby(['Subject Name']).Title.count().sort_values(ascending=False).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps.groupby(['Subject Name']).Title.count().sort_values(ascending=False).head().plot(kind='barh', figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps.groupby(['Subject Name']).Title.count().sort_values(ascending=False).head().plot(kind='pie', figsize=(8,8),startangle=180)\n",
    "plt.ylabel('')\n",
    "#plt.title(\"Most Common Subject Names in Maps Collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps.groupby(['Subject Name']).Title.count().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable that specifies a range to examine\n",
    "# exclude the most-common heading to focus on the next seven values\n",
    "\n",
    "subcounts=maps['Subject Name'].value_counts()\n",
    "\n",
    "totals=subcounts[(subcounts <= 103) & (subcounts>2)]\n",
    "\n",
    "totals.sort_values(ascending=False).plot(kind='pie', figsize=(8,8),startangle=90)\n",
    "plt.ylabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap of Example 2 \n",
    "\n",
    "* select specific columns from multiple different datasets using a variable to store a list of fields\n",
    "* concatenate multiple dataframes into a single dataframe\n",
    "* use groupby to organize datasets for comparison\n",
    "* create basic graphs to compare datasets\n",
    "* explore different graph formats to represent data attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Evaluate Subjects data in a collection<a name=\"ex4\"></a>\n",
    "\n",
    "\n",
    "In this exercise, you will evaluate data in the 'Subject Topical' field in the Maps collection. \n",
    "\n",
    "Based on the output below from maps.info(), it looks like the Subject Topical field is fairly complete in this collection. \n",
    "\n",
    "```\n",
    "maps.info()\n",
    "```\n",
    "\n",
    "```\n",
    "RangeIndex: 161 entries, 0 to 160\n",
    "Data columns (total 7 columns):\n",
    "Title                 161 non-null object\n",
    "Date                  161 non-null object\n",
    "Subject Topical       161 non-null object\n",
    "Subject Name          161 non-null object\n",
    "Subject Geographic    161 non-null object\n",
    "Usage Rights          0 non-null float64\n",
    "colname               161 non-null object\n",
    "```\n",
    "Try using the describe() method to get more details about the values represented within the 'Subject Topical' field. \n",
    "\n",
    "Would plotting the maps titles according to 'Subject Topical' fields assigned to them make an interesting graph? \n",
    "\n",
    "To do this exercise, add code cells below this cell (or use the empty cells provided). Use those cells to check the output from describe() for the maps dataframe, and to generate a plot for numbers of maps titles grouped by Subject Topical. \n",
    "\n",
    "For reference, the solution is demonstrated in the next cells below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution to Exercise 4: Evaluate Subjects data in a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use describe() to evaluate the contents of the 'Subject Topical' field\n",
    "\n",
    "maps['Subject Topical'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from 'describe()' shows that although every item in this collection has a Subject Topical field, it is all the same value, which does not make a very interesting plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a plot for the distribution of Subject Topical field across titles\n",
    "\n",
    "maps.groupby(['Subject Topical']).Title.count().plot(kind='barh',color=['grey'])\n",
    "plt.xlabel('item count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Example 3: Merge information from separate files <a name=\"md3\"></a>\n",
    "\n",
    "Another useful feature of pandas is that it allows you to do SQL-like joins with plain text files.  \n",
    "\n",
    "In this exercise, we will create a merged dataframe from descriptive metadata and file sizes information in separate datasets. We will rename columns in the descriptive metadata dataframe to merge based on columns in our filesizes datasheets. (It's also possible to specify the columns to merge separately for the left and right dataframes if they are not named the same!)  \n",
    "\n",
    "**Learning objectives for this example:**\n",
    "* Review removing empty columns - the first dataset has a large number of columns, some of which have no data\n",
    "* Datatypes can be complicated and lead to potential errors; you may need to specify datatypes for columns\n",
    "* Renaming columns \n",
    "* Merging dataframes \n",
    "* Write a dataframe to a csv output file or other format \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the import statement below and run this cell if your notebook was reset and you need the libraries again\n",
    "\n",
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in collections metadata file as 'metadata' dataframe\n",
    "metadata=pd.read_csv(\"./exampleData/03823_metadata.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use pandas attributes and methods to examine the new dataframe. \n",
    "# Start with the shape attribute to summarize rows and columns.\n",
    "\n",
    "print(metadata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the info method to see column names and item counts in each column\n",
    "\n",
    "metadata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the empty columns using dropna\n",
    "# and re-check the column names and item counts by re-running the info method on the reshaped dataset.\n",
    "\n",
    "metadata.dropna(axis = 1, how ='all', inplace = True)\n",
    "\n",
    "metadata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['Collection Number'].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata=pd.read_csv(\"./exampleData/03823_metadata.txt\", sep='\\t', dtype={'Collection Number':object})\n",
    "\n",
    "metadata['Collection Number'].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the empty columns using dropna\n",
    "\n",
    "metadata.dropna(axis = 1, how ='all', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the head method to see the first n rows\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the second dataframe with the filelist datasheet\n",
    "\n",
    "sizelist=pd.read_csv(\"./exampleData/03823_access_images.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizelist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the second dataframe with the filelist datasheet\n",
    "\n",
    "sizelist=pd.read_csv(\"./exampleData/03823_access_images.csv\", usecols=['Name','Full Path', 'Size'])\n",
    "\n",
    "sizelist.rename(columns={'Name':'AccessName', 'Full Path':'AccessFilePath', 'Size' : 'AccessFileSize'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use shape and info to take a look at the sizelist dataframe.\n",
    "print(sizelist.shape) \n",
    "\n",
    "sizelist.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the head method to see the first n rows of a column\n",
    "\n",
    "sizelist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename a column \n",
    "\n",
    "metadata.rename(columns={'Object file name':'AccessName'}, inplace=True)\n",
    "metadata.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join sizelist data onto the metadata dataframe\n",
    "# and view info for the new, merged dataframe\n",
    "\n",
    "combined = pd.merge(metadata, sizelist,on='AccessName', how='left')\n",
    "\n",
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.AccessFileSize.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['AccessSizeNum'] = combined.AccessFileSize.apply(lambda x: x.replace(' Bytes',''))\n",
    "\n",
    "combined=combined.astype({'AccessSizeNum':'int64'})\n",
    "\n",
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the merged dataframe to a new csv\n",
    "\n",
    "combined.to_csv('./output/accessfilesizes_metadata_03823.csv', index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a third dataframe with the masters files datasheet\n",
    "\n",
    "masters=pd.read_csv(\"./exampleData/03823_masters.csv\", usecols=['Name','Full Path', 'Size'])\n",
    "\n",
    "masters.rename(columns={'Name':'MastersName', 'Full Path':'MasterFilePath', 'Size' : 'MasterFileSize'}, inplace=True)\n",
    "\n",
    "masters['MasterSizeNum'] = masters.MasterFileSize.apply(lambda x: x.replace(' Bytes',''))\n",
    "\n",
    "masters=masters.astype({'MasterSizeNum':'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masters.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masters.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.rename(columns={'filename':'MastersName'}, inplace=True)\n",
    "\n",
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all3 = pd.merge(combined, masters,on='MastersName', how='left')\n",
    "\n",
    "all3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all3.loc[:,['Collection Number','Object', 'MastersName', 'AccessName', 'AccessSizeNum','MasterSizeNum']].head(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercise 5: Other ways to merge <a name=\"ex5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the tail method to see the last n rows of a column\n",
    "sizelist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use python string method to count instances of 'icon'\n",
    "\n",
    "sizelist['AccessName'].str.count(\"icon\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Solution to Exercise 5: Other ways to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Metadata Example: Find and remove duplicates <a name=\"md4\"></a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll=pd.read_csv('./exampleData/coll_dupes_example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll=pd.read_csv('./exampleData/coll_dupes_example.csv', usecols=['Collection Number','Object', 'filename', 'Date created', 'Date modified'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll.Object.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates with drop_duplicates method\n",
    "\n",
    "deduped= coll.drop_duplicates(subset= 'Object', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "31+39125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes_all=coll.loc[coll.Object.duplicated(keep=False), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dupes_all.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes_all.sort_values(['Collection Number','Object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write duplicates dataframe to a csv, sorted by Collection number then by Object field\n",
    "\n",
    "dupes_all.sort_values(['Collection Number','Object']).to_csv('./output/coll_dupes_all_sorted.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can look at new datasheet as a dataframe, or open it in an external spreadsheet program\n",
    "\n",
    "da=pd.read_csv('./output/coll_dupes_all_sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources <a name=\"res\"></a>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
